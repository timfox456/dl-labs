{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network (DNN) Classifier - Iris\n",
    "We will build a relataively simple neuran net to classify IRIS dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - About IRIS Dataset\n",
    "\n",
    "Imagine you are a botanist seeking an automated way to categorize each Iris flower you find. Machine learning provides many algorithms to statistically classify flowers. For instance, a sophisticated machine learning program could classify flowers based on photographs. Our ambitions are more modestâ€”we're going to classify Iris flowers based on the length and width measurements of their [sepals](https://en.wikipedia.org/wiki/Sepal) and [petals](https://en.wikipedia.org/wiki/Petal).\n",
    "\n",
    "The Iris genus entails about 300 species, but our program will only classify the following three:\n",
    "\n",
    "* Iris setosa\n",
    "* Iris virginica\n",
    "* Iris versicolor\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://www.tensorflow.org/images/iris_three_species.jpg\"\n",
    "         alt=\"Petal geometry compared for three iris species: Iris setosa, Iris virginica, and Iris versicolor\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>Figure 1.</b> <a href=\"https://commons.wikimedia.org/w/index.php?curid=170298\">Iris setosa</a> (by <a href=\"https://commons.wikimedia.org/wiki/User:Radomil\">Radomil</a>, CC BY-SA 3.0), <a href=\"https://commons.wikimedia.org/w/index.php?curid=248095\">Iris versicolor</a>, (by <a href=\"https://commons.wikimedia.org/wiki/User:Dlanglois\">Dlanglois</a>, CC BY-SA 3.0), and <a href=\"https://www.flickr.com/photos/33397993@N05/3352169862\">Iris virginica</a> (by <a href=\"https://www.flickr.com/photos/33397993@N05\">Frank Mayfield</a>, CC BY-SA 2.0).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>\n",
    "\n",
    "Fortunately, someone has already created a [data set of 120 Iris flowers](https://en.wikipedia.org/wiki/Iris_flower_data_set) with the sepal and p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine if we are running on google colab\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    RUNNING_IN_COLAB = True\n",
    "except:\n",
    "    RUNNING_IN_COLAB = False\n",
    "\n",
    "print (\"Running in Google COLAB : \", RUNNING_IN_COLAB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# data_location_local = '../data/iris/keras/iris.csv'\n",
    "\n",
    "data_location = \"https://s3.amazonaws.com/elephantscale-public/data/iris/keras/iris.csv\"\n",
    "data_location_local = keras.utils.get_file(fname=os.path.basename(data_location),\n",
    "                                           origin=data_location)\n",
    "\n",
    "iris = pd.read_csv(data_location_local)\n",
    "\n",
    "iris.columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm','Species']\n",
    "\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Shape Data\n",
    "\n",
    "### 3.1 - Select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "x = iris [input_columns]\n",
    "y = iris[['Species']]\n",
    "\n",
    "print (x.head())\n",
    "print('-----')\n",
    "print (y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Encode Labels\n",
    "Our output labels are strings like 'Iris-setosa' and 'Iris-virginica' ..etc.  \n",
    "These are called **categorical variables**  \n",
    "We need to change these to numbers  \n",
    "This is called **encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder =  LabelEncoder()\n",
    "y1 = encoder.fit_transform(y.values) ## need y.values which is an array\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Create train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# supply 'y1' (encoded labels)\n",
    "x_train,x_test, y_train,y_test = train_test_split(x,y1,test_size=0.2,random_state=0) \n",
    "\n",
    "print (\"x_train.shape : \", x_train.shape)\n",
    "print (\"y_train.shape : \", y_train.shape)\n",
    "print (\"x_test.shape : \", x_test.shape)\n",
    "print (\"y_test.shape : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Build the Model\n",
    "Since this is a classifier, here is how we are going to build the neural network\n",
    "- Neurons in Input layer  = input dimensions (4 here)\n",
    "- Neurons in hidden layer = ???\n",
    "- Neurons in Output layer = output classes (3 here)\n",
    "- Output activation is 'softmax'\n",
    "\n",
    "### TODO : Sketch the neural net\n",
    "- What is the input dimensions\n",
    "- how many neurons in layers\n",
    "- how many output neurons\n",
    "\n",
    "<img src=\"../assets/images/neural-net-unknown.png\" style=\"width:40%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(input_columns)\n",
    "output_clases = 3 \n",
    "print (\"input_dim : \", input_dim, \", output classes : \", output_clases)\n",
    "\n",
    "## TODO : construct the network\n",
    "##     - number of neurons for 'intput_layer' = input_dim\n",
    "##     - number of neurons for 'hidden_1' layer = 8  (start with 8 for now)\n",
    "##     - number of neurons for 'output_layer' = output_classes\n",
    "\n",
    "## TODO : set activation functions as follows \n",
    "##     - activation function for both 'ainput_layer' and 'hidden_1' = tf.nn.relu\n",
    "##     - activation function for final 'output_layer' = tf.nn.softmax\n",
    "model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(units=???, activation=???, input_dim=input_dim),\n",
    "            tf.keras.layers.Dense(units=???, activation=???),\n",
    "            tf.keras.layers.Dense(units=???,  activation=???)\n",
    "            ])\n",
    "\n",
    "# loss = 'sparse_categorical_crossentropy'  or 'categorical_crossentropy'\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "                 optimizer=tf.keras.optimizers.Adam(), # or 'adam', \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "print (model.summary())\n",
    "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is fairly boiler plate code\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "app_name = 'classification-iris'\n",
    "\n",
    "# timestamp  = datetime.datetime.now().strftime(\"%Y-%m-%d--%H-%M-%S\")\n",
    "\n",
    "tb_top_level_dir= '/tmp/tensorboard-logs'\n",
    "\n",
    "tb_app_dir = os.path.join (tb_top_level_dir, app_name)\n",
    "\n",
    "tb_logs_dir = os.path.join (tb_app_dir, datetime.datetime.now().strftime(\"%H-%M-%S\"))\n",
    "\n",
    "\n",
    "print (\"Saving TB logs to : \" , tb_logs_dir)\n",
    "\n",
    "#clear out old logs\n",
    "shutil.rmtree ( tb_app_dir, ignore_errors=True )\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_logs_dir, write_graph=True, \n",
    "                                                      write_images=True, histogram_freq=1)\n",
    "\n",
    "## This will embed Tensorboard right here in jupyter!\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $tb_logs_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 : Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## TODO start with 100 epochs\n",
    "epochs = ???\n",
    "\n",
    "print (\"training starting ...\")\n",
    "history = model.fit(\n",
    "              x_train, y_train,\n",
    "              epochs=epochs, validation_split = 0.2, verbose=1,\n",
    "              callbacks=[tensorboard_callback])\n",
    "\n",
    "print (\"training done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 : Plot History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 : Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Predictions\n",
    "In the above output, for each test input, the softmax layer, produces 3 numbers.  \n",
    "These numbers are probabilities.  If you add them up, you will get 1.0  \n",
    "We want to choose the output that has the highest probability.  \n",
    "\n",
    "For example `(0.03086184, 0.33362046, 0.6355177)` means  \n",
    "- class 1 has prob of 0.03  or 3%\n",
    "- class 2 has prob of 0.33  or 33%\n",
    "- class 3 has prob of 0.63  or 63%\n",
    "\n",
    "So we choose the class with highest probability as prediction : class 3\n",
    "\n",
    "\n",
    "We can get class predictions directly as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use 'predict_classes' instead of 'predict'\n",
    "y_pred = np.argmax(predictions, axis=-1)\n",
    "print ('prediction classes: ', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 : Evaluate the model\n",
    "\n",
    "### 9.1 - Print out metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = model.metrics_names\n",
    "print (\"model metrics : \" , metric_names)\n",
    "\n",
    "metrics = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "for idx, metric in enumerate(metric_names):\n",
    "    print (\"Metric : {} = {:,.2f}\".format (metric_names[idx], metrics[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 - Confussion Matrix\n",
    "Since this is a classification problem, confusion matrix is very effective way to evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plain confusion matrix \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels = [0,1,2])\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize = (8,5))\n",
    "\n",
    "# colormaps : cmap=\"YlGnBu\" , cmap=\"Greens\", cmap=\"Blues\",  cmap=\"Reds\"\n",
    "sns.heatmap(cm, annot=True, cmap=\"Reds\", fmt='d').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 - Metrics calculated from Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(classification_report(y_test, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO : Intepret confusion matrix\n",
    "Instructor will walk you through the matrix.  \n",
    "Answer these questions\n",
    "- which class is classified correctly mostly\n",
    "- which class is classified incorrectly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 : Improve the Model\n",
    "\n",
    "Inspect the following\n",
    "- What is the metric 'accuracy' in step 9.1\n",
    "- And verify this with tensorboard (port 6066)\n",
    "\n",
    "Most likely, we didn't get a great accuracy.  \n",
    "How can we improve it?\n",
    "\n",
    "**Try the following ideas** \n",
    "\n",
    "- **Idea-1 : Increase neurons in hidden layer**  \n",
    "  - In Step-4, increase hidden layer neurons from 8 --> 64  \n",
    "  - Click 'Kernel --> Restart and Run all Cells'  \n",
    "  - Hopefully you should see improvement in the accuracy.  \n",
    "  - Check  accuracy metrics / confusion matrix / tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 : Mismatched Output Classes\n",
    "\n",
    "In **Step-4**  when defining the network, change the number of neurons in the **final softmax layer to 2**.\n",
    "\n",
    "Re-run this notebook.\n",
    "\n",
    "What kind of error do you get?  This is a good error to remember :-) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Compact Code\n",
    "Here is the compact code : [classification-1b-iris-compact.ipynb](classification-1b-iris-compact.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
